{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of encoding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aproca/MNIST_To_CIFAR10AdvRep/blob/master/MNIST_encoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5msF-SxoYl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "\n",
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSF6dDFZqnhG",
        "colab_type": "code",
        "outputId": "c7c0a175-63de-489f-8a76-3a6ab54c3958",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from sklearn.preprocessing import normalize\n",
        "# Convert sklearn 'datasets bunch' object to Pandas DataFrames\n",
        "y = pd.Series(mnist.target).astype('int').astype('category')\n",
        "X = pd.DataFrame(mnist.data)\n",
        "\n",
        "X.shape, y.shape\n",
        "\n",
        "num_images = X.shape[1]\n",
        "X.columns = ['pixel_'+str(x) for x in range(num_images)]\n",
        "\n",
        "# print first row of X\n",
        "X.head(1)\n",
        "\n",
        "#X = normalize(X,norm='l1')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel_0</th>\n",
              "      <th>pixel_1</th>\n",
              "      <th>pixel_2</th>\n",
              "      <th>pixel_3</th>\n",
              "      <th>pixel_4</th>\n",
              "      <th>pixel_5</th>\n",
              "      <th>pixel_6</th>\n",
              "      <th>pixel_7</th>\n",
              "      <th>pixel_8</th>\n",
              "      <th>pixel_9</th>\n",
              "      <th>pixel_10</th>\n",
              "      <th>pixel_11</th>\n",
              "      <th>pixel_12</th>\n",
              "      <th>pixel_13</th>\n",
              "      <th>pixel_14</th>\n",
              "      <th>pixel_15</th>\n",
              "      <th>pixel_16</th>\n",
              "      <th>pixel_17</th>\n",
              "      <th>pixel_18</th>\n",
              "      <th>pixel_19</th>\n",
              "      <th>pixel_20</th>\n",
              "      <th>pixel_21</th>\n",
              "      <th>pixel_22</th>\n",
              "      <th>pixel_23</th>\n",
              "      <th>pixel_24</th>\n",
              "      <th>pixel_25</th>\n",
              "      <th>pixel_26</th>\n",
              "      <th>pixel_27</th>\n",
              "      <th>pixel_28</th>\n",
              "      <th>pixel_29</th>\n",
              "      <th>pixel_30</th>\n",
              "      <th>pixel_31</th>\n",
              "      <th>pixel_32</th>\n",
              "      <th>pixel_33</th>\n",
              "      <th>pixel_34</th>\n",
              "      <th>pixel_35</th>\n",
              "      <th>pixel_36</th>\n",
              "      <th>pixel_37</th>\n",
              "      <th>pixel_38</th>\n",
              "      <th>pixel_39</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel_744</th>\n",
              "      <th>pixel_745</th>\n",
              "      <th>pixel_746</th>\n",
              "      <th>pixel_747</th>\n",
              "      <th>pixel_748</th>\n",
              "      <th>pixel_749</th>\n",
              "      <th>pixel_750</th>\n",
              "      <th>pixel_751</th>\n",
              "      <th>pixel_752</th>\n",
              "      <th>pixel_753</th>\n",
              "      <th>pixel_754</th>\n",
              "      <th>pixel_755</th>\n",
              "      <th>pixel_756</th>\n",
              "      <th>pixel_757</th>\n",
              "      <th>pixel_758</th>\n",
              "      <th>pixel_759</th>\n",
              "      <th>pixel_760</th>\n",
              "      <th>pixel_761</th>\n",
              "      <th>pixel_762</th>\n",
              "      <th>pixel_763</th>\n",
              "      <th>pixel_764</th>\n",
              "      <th>pixel_765</th>\n",
              "      <th>pixel_766</th>\n",
              "      <th>pixel_767</th>\n",
              "      <th>pixel_768</th>\n",
              "      <th>pixel_769</th>\n",
              "      <th>pixel_770</th>\n",
              "      <th>pixel_771</th>\n",
              "      <th>pixel_772</th>\n",
              "      <th>pixel_773</th>\n",
              "      <th>pixel_774</th>\n",
              "      <th>pixel_775</th>\n",
              "      <th>pixel_776</th>\n",
              "      <th>pixel_777</th>\n",
              "      <th>pixel_778</th>\n",
              "      <th>pixel_779</th>\n",
              "      <th>pixel_780</th>\n",
              "      <th>pixel_781</th>\n",
              "      <th>pixel_782</th>\n",
              "      <th>pixel_783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows Ã— 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   pixel_0  pixel_1  pixel_2  ...  pixel_781  pixel_782  pixel_783\n",
              "0      0.0      0.0      0.0  ...        0.0        0.0        0.0\n",
              "\n",
              "[1 rows x 784 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbFUsE1Lq64E",
        "colab_type": "code",
        "outputId": "2b0b0b8b-5897-45ec-b4ff-49c82d915bb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn import preprocessing\n",
        "# First row is first image\n",
        "first_image = X.loc[0,:]\n",
        "first_label = y[0]\n",
        "\n",
        "# 784 columns correspond to 28x28 image\n",
        "plottable_image = np.reshape(first_image.values, (28, 28))\n",
        "\n",
        "#scaled_image = preprocessing.scale(plottable_image)\n",
        "\n",
        "print(y[1:10])\n",
        "\n",
        "#test\n",
        "print(plottable_image[10][12])\n",
        "\n",
        "# Plot the image\n",
        "plt.imshow(plottable_image, cmap='gray_r')\n",
        "plt.title('Digit Label: {}'.format(first_label))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1    0\n",
            "2    4\n",
            "3    1\n",
            "4    9\n",
            "5    2\n",
            "6    1\n",
            "7    3\n",
            "8    1\n",
            "9    4\n",
            "dtype: category\n",
            "Categories (10, int64): [0, 1, 2, 3, ..., 6, 7, 8, 9]\n",
            "253.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nN8uUw2+Wqf8HVc1qtVz/H70AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzQ9QlqdwIqH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "scaled_image = min_max_scaler.fit_transform(plottable_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8zBW4hStoU6",
        "colab_type": "code",
        "outputId": "d772b057-e9de-40ed-8bb1-692cb937a63f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def rounding_func(x):\n",
        "  if x < 0.5:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1\n",
        "\n",
        "  \n",
        "rounding_func(0.6561264822134387)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvbecRzxrWzm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def redefine_image(scaled_image):\n",
        "  for row in range(len(scaled_image)):\n",
        "    for column in range(len(scaled_image[row])):\n",
        "      if scaled_image[row][column] != 0.0:\n",
        "        x = scaled_image[row][column]\n",
        "        scaled_image[row][column] = rounding_func(x)\n",
        "        \n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m-tYmmZzlc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Create mapping func \"\"\"\n",
        "\n",
        "\n",
        "def mapping_func(image,row, column):\n",
        "  if row == 27 and column == 27:\n",
        "    first = image[row][column]\n",
        "    second = 0.0\n",
        "    third = 0.0\n",
        "    fourth = 0.0\n",
        "  elif row == 27:\n",
        "    first = image[row][column]\n",
        "    second = image[row][column+1]\n",
        "    third = 0.0\n",
        "    fourth = 0.0\n",
        "  elif column == 27:\n",
        "    first = image[row][column]\n",
        "    second = 0.0\n",
        "    third = image[row+1][column]\n",
        "    fourth = 0.0  \n",
        "  else:\n",
        "    first = image[row][column]\n",
        "    second = image[row][column+1]\n",
        "    third = image[row+1][column]\n",
        "    fourth = image[row+1][column+1]\n",
        "\n",
        " \n",
        "  \n",
        "  if first == 0.0 and second == 0.0 and third == 0.0 and fourth == 0.0:\n",
        "    return ord('p')\n",
        "  \n",
        "  \n",
        "  first = rounding_func(first)\n",
        "  second = rounding_func(second)\n",
        "  third =  rounding_func(third)\n",
        "  fourth =  rounding_func(fourth)\n",
        "  \n",
        "   \n",
        "  if first == 1.0 and second == 0.0 and third == 0.0 and fourth == 0.0:\n",
        "    return ord('a')\n",
        "  elif first == 0.0 and second == 1.0 and third == 0.0 and fourth == 0.0:\n",
        "    return ord('b')\n",
        "  elif first == 0.0 and second == 0.0 and third == 1.0 and fourth == 0.0:\n",
        "    return ord('c')\n",
        "  elif first == 0.0 and second == 0.0 and third == 0.0 and fourth == 1.0:\n",
        "    return ord('d')\n",
        "  elif first == 1.0 and second == 1.0 and third == 0.0 and fourth == 0.0:\n",
        "    return ord('e')\n",
        "  elif first == 0.0 and second == 0.0 and third == 1.0 and fourth == 1.0:\n",
        "    return ord('f')\n",
        "  elif first == 1.0 and second == 0.0 and third == 1.0 and fourth == 0.0:\n",
        "    return ord('g')\n",
        "  elif first == 0.0 and second == 1.0 and third == 0.0 and fourth == 1.0:\n",
        "    return ord('h')\n",
        "  elif first == 0.0 and second == 0.0 and third == 0.0 and fourth == 0.0:\n",
        "    return ord('i')\n",
        "  elif first == 0.0 and second == 1.0 and third == 1.0 and fourth == 0.0:\n",
        "    return ord('j')\n",
        "  elif first == 1.0 and second == 1.0 and third == 1.0 and fourth == 0.0:\n",
        "    return ord('k')\n",
        "  elif first == 1.0 and second == 1.0 and third == 0.0 and fourth == 1.0:\n",
        "    return ord('l')\n",
        "  elif first == 0.0 and second == 1.0 and third == 1.0 and fourth == 1.0:\n",
        "    return ord('m')\n",
        "  elif first == 1.0 and second == 0.0 and third == 1.0 and fourth == 1.0:\n",
        "    return ord('n')\n",
        "  elif first == 1.0 and second == 1.0 and third == 1.0 and fourth == 1.0:\n",
        "    return ord('o')\n",
        "  else:\n",
        "    return ord('q')\n",
        " \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd7VN_YB1FKh",
        "colab_type": "code",
        "outputId": "5acedbaf-36f3-4ffc-ec32-c40d796b0de3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "\"\"\" Better? Do rounding and \"\"\"\n",
        "\n",
        "sample = len(X)\n",
        "\n",
        "all_image_chars = [] \n",
        "\n",
        "for im in range(len(0:10)):\n",
        "  image_chars = []   \n",
        "  #print(im)\n",
        "\n",
        "  image = X.loc[im,:]\n",
        "  label = y[im]\n",
        "  \n",
        "  #print(\"***\",label)\n",
        "  plottable_image = np.reshape(image.values, (28, 28))\n",
        "\n",
        "  min_max_scaler = preprocessing.MinMaxScaler()\n",
        "  scaled_image = min_max_scaler.fit_transform(plottable_image)\n",
        "  \n",
        " \n",
        "  \n",
        "  for row in range(len(scaled_image)):\n",
        "    for column in range(len(scaled_image[row])):\n",
        "       #image_chars.append(int(mapping_func(scaled_image,row,column)))\n",
        "        image_chars.append(mapping_func(scaled_image,row,column))\n",
        "  \n",
        "  image_chars.append(label)\n",
        "  all_image_chars.append(image_chars)  \n",
        "  \n",
        "        \n",
        "all_image_chars = np.array(all_image_chars)\n",
        "#print(len(all_image_chars))\n",
        "\n",
        "print(all_image_chars[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112\n",
            " 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112\n",
            " 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112\n",
            " 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112\n",
            " 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112\n",
            " 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112\n",
            " 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 105 105 105\n",
            " 105 105 100 102  99 100 102 102 102  99 112 112 112 112 112 112 112 112\n",
            " 112 112 112 105 105 105 100 102 102 102 102 102 109 111 110 109 111 111\n",
            " 111 103 112 112 112 112 112 112 112 112 112 112 105 100 102 102 109 111\n",
            " 111 111 111 111 111 107 101 101 101 101 101  97 112 112 112 112 112 112\n",
            " 112 112 112 112 105 104 111 111 111 111 111 111 111 111 111 103 105 105\n",
            " 105 105 105 112 112 112 112 112 112 112 112 112 112 112 105  98 108 107\n",
            " 108 111 111 107 101 101 108 103 112 112 112 112 112 112 112 112 112 112\n",
            " 112 112 112 112 112 112 112 105  98  97 104 111 107  97 105 105  98  97\n",
            " 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112\n",
            " 105 105 104 111 110  99 105 112 112 112 112 112 112 112 112 112 112 112\n",
            " 112 112 112 112 112 112 112 112 112 112 112 112  98 108 111 103 105 112\n",
            " 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112\n",
            " 112 112 112 112 105  98 108 110 102  99 105 105 112 112 112 112 112 112\n",
            " 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 105  98 108\n",
            " 111 110  99 105 105 112 112 112 112 112 112 112 112 112 112 112 112 112\n",
            " 112 112 112 112 112 112 112 112 105  98 108 111 110 102  99 105 112 112\n",
            " 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112\n",
            " 112 105  98 101 108 111 110  99 112 112 112 112 112 112 112 112 112 112\n",
            " 112 112 112 112 112 112 112 112 112 112 112 112 105 105 104 111 111 103\n",
            " 105 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112\n",
            " 112 112 112 105 100 102 109 111 111 103 105 112 112 112 112 112 112 112\n",
            " 112 112 112 112 112 112 112 112 112 112 112 105 100 102 109 111 111 111\n",
            " 111 103 105 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112\n",
            " 112 105 105 100 109 111 111 111 111 107 101  97 112 112 112 112 112 112\n",
            " 112 112 112 112 112 112 112 112 112 105 105 100 102 109 111 111 111 107\n",
            " 101  97 105 112 112 112 112 112 112 112 112 112 112 112 112 112 112 105\n",
            " 100 102 102 109 111 111 111 107 101  97 105 105 112 112 112 112 112 112\n",
            " 112 112 112 112 112 112 112 105 100 102 109 111 111 111 111 111 107  97\n",
            " 105 105 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 100\n",
            " 109 111 111 111 111 111 107 101  97 105 112 112 112 112 112 112 112 112\n",
            " 112 112 112 112 112 112 112 112 112  98 101 101 101 101 101 101  97 105\n",
            " 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112\n",
            " 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112\n",
            " 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112\n",
            " 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112\n",
            " 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112\n",
            " 112 112 112 112 112 112 112 112 112 112   5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hz334bZfd9zq",
        "colab_type": "code",
        "outputId": "bd084ba9-bcab-4040-89fd-84513db5ceb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(all_image_chars)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbmbrIpFv1D6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "#pd.DataFrame(all_image_chars).to_csv(\"mnist_ascii_70000_2.csv\")\n",
        "pd.DataFrame(all_image_chars[1:10000]).to_csv(\"mnist_language_test.csv\", index = False)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KGnFDUifLgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"mnist_language_test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8ErOp8uiImq",
        "colab_type": "code",
        "outputId": "d0e04693-93da-4ca0-9015-4ffd8aeca09f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "from google.colab import files\n",
        "files.download( \"mnist_ascii_70000_2.csv\" )  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------\n",
            "Exception happened during processing of request from ('::ffff:127.0.0.1', 37834, 0, 0)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 320, in _handle_request_noblock\n",
            "    self.process_request(request, client_address)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 351, in process_request\n",
            "    self.finish_request(request, client_address)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 364, in finish_request\n",
            "    self.RequestHandlerClass(request, client_address, self)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 724, in __init__\n",
            "    self.handle()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 418, in handle\n",
            "    self.handle_one_request()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 406, in handle_one_request\n",
            "    method()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 639, in do_GET\n",
            "    self.copyfile(f, self.wfile)\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 800, in copyfile\n",
            "    shutil.copyfileobj(source, outputfile)\n",
            "  File \"/usr/lib/python3.6/shutil.py\", line 82, in copyfileobj\n",
            "    fdst.write(buf)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 803, in write\n",
            "    self._sock.sendall(b)\n",
            "ConnectionResetError: [Errno 104] Connection reset by peer\n",
            "----------------------------------------\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnsVutbDZ81N",
        "colab_type": "code",
        "outputId": "bb1dd7e4-efc6-4375-f159-f1188570f7c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "train_file = 'https://raw.githubusercontent.com/dlatorre-mf/mnist-reprogramming-adv/master/mnist_language_new.csv'\n",
        "datatrain = pd.read_csv(train_file)\n",
        "\n",
        "\n",
        "\n",
        "print(datatrain.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "y = datatrain['784'].values\n",
        "X = datatrain.drop(['784'],1).values\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n",
        "\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "torch_X_train = torch.from_numpy(X_train).type(torch.LongTensor)\n",
        "torch_y_train = torch.from_numpy(y_train).type(torch.LongTensor) # data type is long\n",
        "\n",
        "# create feature and targets tensor for test set.\n",
        "torch_X_test = torch.from_numpy(X_test).type(torch.LongTensor)\n",
        "torch_y_test = torch.from_numpy(y_test).type(torch.LongTensor) # data type is long\n",
        "\n",
        "# Pytorch train and test sets\n",
        "train = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\n",
        "test = torch.utils.data.TensorDataset(torch_X_test,torch_y_test)\n",
        "\n",
        "# data loader\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = False)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6, 786)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-eb23620310f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtorch_X_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mtorch_y_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# data type is long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, int64, int32, int16, int8, and uint8."
          ]
        }
      ]
    }
  ]
}